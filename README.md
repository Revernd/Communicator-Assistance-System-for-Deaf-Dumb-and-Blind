# Communicator-Assistance-System-for-Deaf-Dumb-and-Blind

Communication is an integral part of our daily life for interacting with others, but it is challenging for differently-abled people like deaf and/or dumb to use sign language for essential communication. This sign language is still not adequate for blind people, they use braille script to read and their voice for communication. This research paper aims to develop a communicator assistance model for the interaction among differently-abled people like Blind and deaf and/or dumb. A neural network model SignNet has been designed to detect the sign-language from deaf and/or dumb per-son through webcam with the help of OpenCV and construct the words which can be converted to speech for blind people; the whole process would be reverse for responding to the conversation. Our neural network works with an accuracy of 99%, with batches of size 20 running through 10 epochs, taking 1344 steps to finish an epoch. Our model can be used where the interaction with/between challenged people is more like to happen, like in schools for specially challenged people or workplace, as this application is an asset to them in communicating with others and expressing their voice.

# Our Model works in with Architecture
![image](https://user-images.githubusercontent.com/61039935/212501448-429739a5-50a6-4cec-ab11-c04cc15fae1e.png)

# CAN:
![Screenshot (207)](https://user-images.githubusercontent.com/61039935/212501503-0a9e1e14-8024-41b4-aa88-a4070b77f218.png)


